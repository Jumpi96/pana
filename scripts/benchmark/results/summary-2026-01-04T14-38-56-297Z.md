# LLM Provider Benchmark Results

**Date:** Invalid Date
**Test Cases:** 20
**Providers:** OpenAI, Anthropic, Google

## Summary

| Provider | Model | Accuracy (MAPE) | Avg Latency | Cost/1000 calls | Success Rate | Item Accuracy |
|----------|-------|-----------------|-------------|-----------------|--------------|---------------|
| Anthropic | claude-3-haiku-20240307 | 36.9% | 2074ms | $0.42 | 18/20 | 100% |
| OpenAI | gpt-4o-mini | 52.8% | 3740ms | $0.21 | 20/20 | 95% |
| Google | gemini-2.0-flash | 41.1% | 1775ms | $0.12 | 20/20 | 95% |

## Accuracy by Macro Type

| Provider | Calories MAPE | Protein MAPE | Carbs MAPE | Fat MAPE |
|----------|---------------|--------------|------------|----------|
| Anthropic | 32.4% | 34.5% | 59.2% | 21.8% |
| OpenAI | 42.4% | 51.7% | 74.7% | 42.4% |
| Google | 35.1% | 47.7% | 41% | 40.6% |

## Results by Category

### Simple

- **OpenAI:** 9.6% avg MAPE
- **Anthropic:** 24.0% avg MAPE
- **Google:** 9.9% avg MAPE

### Quantity

- **OpenAI:** 10.5% avg MAPE
- **Anthropic:** 18.4% avg MAPE
- **Google:** 20.8% avg MAPE

### Spanish

- **OpenAI:** 21.9% avg MAPE
- **Anthropic:** 29.5% avg MAPE
- **Google:** 14.7% avg MAPE

### Multi-item

- **OpenAI:** 108.5% avg MAPE
- **Anthropic:** 43.3% avg MAPE
- **Google:** 83.3% avg MAPE

### Vague

- **OpenAI:** 45.9% avg MAPE
- **Anthropic:** 35.3% avg MAPE
- **Google:** 43.1% avg MAPE

### Alcohol

- **OpenAI:** 115.4% avg MAPE
- **Anthropic:** 100.5% avg MAPE
- **Google:** 63.8% avg MAPE

## Errors

- **Anthropic** on "Toast with butter and jam": Invalid item: invalid unit "teaspoon" for Butter
- **Anthropic** on "Glass of red wine": Invalid item: invalid unit "glass" for Red Wine

## Recommendation

- **Most Accurate:** Anthropic (claude-3-haiku-20240307) with 36.9% MAPE
- **Cheapest:** Google (gemini-2.0-flash) at $0.12/1000 calls
- **Fastest:** Google (gemini-2.0-flash) at 1775ms avg latency

**Overall Recommendation:** Google (gemini-2.0-flash)
- Weighted score: 61.4 (accuracy 50%, cost 30%, speed 20%)